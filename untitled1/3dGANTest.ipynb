{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import time\n",
    "import StructureManager\n",
    "from os import system, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def generate_heatmap(data, epoch):\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    im = ax.imshow(data)\n",
    "    \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            text = ax.text(j, i, data[i, j],\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()\n",
    "\n",
    "def build_generator():\n",
    "    \"\"\"\n",
    "    Create a Generator Model with hyperparameters values defined as follows\n",
    "    :return: Generator network\n",
    "     \"\"\"\n",
    "    z_size = 200\n",
    "    gen_filters = [64, 32, 16, 1]\n",
    "    gen_kernel_sizes = [2, 4, 4, 4, 4]\n",
    "    gen_strides = [1, 2, 2, 2]\n",
    "    gen_input_shape = (1, 1, 1, z_size)\n",
    "    gen_activations = ['relu', 'relu', 'relu', 'tanh']\n",
    "    gen_convolutional_blocks = 4\n",
    "    \n",
    "    input_layer = layers.Input(shape=gen_input_shape)\n",
    "    \n",
    "    # First 3D transpose convolution(or 3D deconvolution) block\n",
    "    a = layers.Conv3DTranspose(filters=gen_filters[0], \n",
    "                        kernel_size=gen_kernel_sizes[0],\n",
    "                        strides=gen_strides[0])(input_layer)\n",
    "    a = layers.BatchNormalization()(a, training=True)\n",
    "    a = layers.Activation(activation='relu')(a)\n",
    "    \n",
    "    # Next 4 3D transpose convolution(or 3D deconvolution) blocks\n",
    "    for i in range(gen_convolutional_blocks - 1):\n",
    "        a = layers.Conv3DTranspose(filters=gen_filters[i + 1], \n",
    "                            kernel_size=gen_kernel_sizes[i + 1],\n",
    "                            strides=gen_strides[i + 1], padding='same')(a)\n",
    "        a = layers.BatchNormalization()(a, training=True)\n",
    "        a = layers.Activation(activation=gen_activations[i + 1])(a)\n",
    "    gen_model = Model(inputs=input_layer, outputs=a)\n",
    "    gen_model.summary()\n",
    "    return gen_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    \"\"\"\n",
    "    Create a Discriminator Model using hyperparameters values defined as follows\n",
    "    :return: Discriminator network\n",
    "    \"\"\"\n",
    "    dis_input_shape = (16, 16, 16, 1)\n",
    "    dis_filters = [16, 32, 64, 1]\n",
    "    dis_kernel_sizes = [4, 4, 4, 4]\n",
    "    dis_strides = [2, 2, 2, 2]\n",
    "    dis_paddings = ['same', 'same', 'same', 'same', 'valid']\n",
    "    dis_alphas = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "    dis_activations = ['leaky_relu', 'leaky_relu', 'leaky_relu', \n",
    "                       'sigmoid']\n",
    "    dis_convolutional_blocks = 4\n",
    "\n",
    "    dis_input_layer = layers.Input(shape=dis_input_shape)\n",
    "    \n",
    "    # The first 3D Convolutional block\n",
    "    a = layers.Conv3D(filters=dis_filters[0],\n",
    "               kernel_size=dis_kernel_sizes[0],\n",
    "               strides=dis_strides[0],\n",
    "               padding=dis_paddings[0])(dis_input_layer)\n",
    "    a = layers.BatchNormalization()(a, training=True)\n",
    "    a = layers.LeakyReLU(dis_alphas[0])(a)\n",
    "    \n",
    "    # Next 4 3D Convolutional Blocks\n",
    "    for i in range(dis_convolutional_blocks - 1):\n",
    "        a = layers.Conv3D(filters=dis_filters[i + 1],\n",
    "                   kernel_size=dis_kernel_sizes[i + 1],\n",
    "                   strides=dis_strides[i + 1],\n",
    "                   padding=dis_paddings[i + 1])(a)\n",
    "        a = layers.BatchNormalization()(a, training=True)\n",
    "        if dis_activations[i + 1] == 'leaky_relu':\n",
    "            a = layers.LeakyReLU(dis_alphas[i + 1])(a)\n",
    "        elif dis_activations[i + 1] == 'sigmoid':\n",
    "            a = layers.Activation(activation='sigmoid')(a)\n",
    "    \n",
    "    dis_model = Model(inputs=dis_input_layer, outputs=a)\n",
    "    print(dis_model.summary())\n",
    "    return dis_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "gen_learning_rate = 0.00002\n",
    "dis_learning_rate = 0.0008\n",
    "beta = 0.5\n",
    "batch_size = 32\n",
    "z_size = 200\n",
    "DIR_PATH = ''\n",
    "generated_structures_dir = 'generated_volumes'\n",
    "log_dir = '.\\\\logs'\n",
    "epochs = 100000\n",
    "seed = np.random.normal(0, 0.33, size=[batch_size, 1, 1, 1, z_size]).astype(np.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 1, 1, 1, 200)]    0         \n_________________________________________________________________\nconv3d_transpose_4 (Conv3DTr (None, 2, 2, 2, 64)       102464    \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 2, 2, 2, 64)       256       \n_________________________________________________________________\nactivation_5 (Activation)    (None, 2, 2, 2, 64)       0         \n_________________________________________________________________\nconv3d_transpose_5 (Conv3DTr (None, 4, 4, 4, 32)       131104    \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 4, 4, 4, 32)       128       \n_________________________________________________________________\nactivation_6 (Activation)    (None, 4, 4, 4, 32)       0         \n_________________________________________________________________\nconv3d_transpose_6 (Conv3DTr (None, 8, 8, 8, 16)       32784     \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 8, 8, 8, 16)       64        \n_________________________________________________________________\nactivation_7 (Activation)    (None, 8, 8, 8, 16)       0         \n_________________________________________________________________\nconv3d_transpose_7 (Conv3DTr (None, 16, 16, 16, 1)     1025      \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 16, 16, 16, 1)     4         \n_________________________________________________________________\nactivation_8 (Activation)    (None, 16, 16, 16, 1)     0         \n=================================================================\nTotal params: 267,829\nTrainable params: 267,603\nNon-trainable params: 226\n_________________________________________________________________\n",
      "Model: \"model_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         [(None, 16, 16, 16, 1)]   0         \n_________________________________________________________________\nconv3d_4 (Conv3D)            (None, 8, 8, 8, 16)       1040      \n_________________________________________________________________\nbatch_normalization_12 (Batc (None, 8, 8, 8, 16)       64        \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 8, 16)       0         \n_________________________________________________________________\nconv3d_5 (Conv3D)            (None, 4, 4, 4, 32)       32800     \n_________________________________________________________________\nbatch_normalization_13 (Batc (None, 4, 4, 4, 32)       128       \n_________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 4, 32)       0         \n_________________________________________________________________\nconv3d_6 (Conv3D)            (None, 2, 2, 2, 64)       131136    \n_________________________________________________________________\nbatch_normalization_14 (Batc (None, 2, 2, 2, 64)       256       \n_________________________________________________________________\nleaky_re_lu_5 (LeakyReLU)    (None, 2, 2, 2, 64)       0         \n_________________________________________________________________\nconv3d_7 (Conv3D)            (None, 1, 1, 1, 1)        4097      \n_________________________________________________________________\nbatch_normalization_15 (Batc (None, 1, 1, 1, 1)        4         \n_________________________________________________________________\nactivation_9 (Activation)    (None, 1, 1, 1, 1)        0         \n=================================================================\nTotal params: 169,525\nTrainable params: 169,299\nNon-trainable params: 226\n_________________________________________________________________\nNone\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Create instances\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# Specify optimizer \n",
    "gen_optimizer = tf.keras.optimizers.Adam(lr=gen_learning_rate, beta_1=beta)\n",
    "dis_optimizer = tf.keras.optimizers.Adam(lr=dis_learning_rate, beta_1=0.9)\n",
    "\n",
    "# Compile networks\n",
    "generator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=dis_optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "adversarial_model = tf.keras.models.Sequential()\n",
    "adversarial_model.add(generator)\n",
    "adversarial_model.add(discriminator)\n",
    "adversarial_model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr=gen_learning_rate, beta_1=beta))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "dir = \"{}\\{}\".format(log_dir, time.time())\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=dir)\n",
    "tensorboard.set_model(generator)\n",
    "tensorboard.set_model(discriminator)\n",
    "writer = tf.summary.create_file_writer(dir)\n",
    "writer.set_as_default()\n",
    "labels_real = np.reshape([1] * batch_size, (-1, 1, 1, 1, 1))\n",
    "labels_fake = np.reshape([0] * batch_size, (-1, 1, 1, 1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "d = \"..\\\\lamps484\"\n",
    "d2 = \"..\\\\structures16\"\n",
    "dataset_list = StructureManager.load_structure_blocks(d2, (16,16,16))\n",
    "\n",
    "scalar = len(StructureManager.globalPalette)-1\n",
    "processed_inputs = np.subtract(np.multiply(np.divide(dataset_list, scalar),2),1)\n",
    "processed_inputs = np.expand_dims(processed_inputs, axis=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def generate_save_structures(model, epoch, test_input):\n",
    "  predictions = model(test_input, training=False)\n",
    "  processed_predictions = np.divide(np.multiply(np.add(predictions, 1), scalar),2)\n",
    "  processed_predictions = processed_predictions.astype(int)\n",
    "  generate_heatmap(np.squeeze(processed_predictions)[0][0], epoch)\n",
    "  for prediction in processed_predictions:\n",
    "      StructureManager.create_nbt_from_3d(np.squeeze(prediction), epoch)\n",
    "      \n",
    "def convert_predictions(data):\n",
    "      processed_predictions = np.around(np.squeeze(np.divide(np.multiply(np.add(data, 1), scalar),2)))\n",
    "      processed_predictions = processed_predictions.astype(int)\n",
    "      return processed_predictions\n",
    "\n",
    "def get_structures(model, test_input):\n",
    "  predictions = model(test_input, training=False)\n",
    "  processed_predictions = convert_predictions(predictions)\n",
    "  return processed_predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def write_log(name, value, epoch):\n",
    "    tf.summary.scalar(name, value, epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processed_inputs = volumes = np.full((100,16,16,16, 1), 0.5).astype(np.float)\n",
    "counter = 0\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch:\", epoch)\n",
    "    gen_losses = []\n",
    "    dis_losses = []\n",
    "    number_of_batches = int(processed_inputs.shape[0] / batch_size)\n",
    "    for index in range(number_of_batches):\n",
    "        z_sample = np.random.normal(0, 0.33, size=[batch_size, 1, 1, 1, \n",
    "                            z_size]).astype(np.float32)\n",
    "        struct_batch = processed_inputs[index * batch_size:(index + 1) * batch_size, :, :, :]\n",
    "        gen_structs = generator.predict(z_sample)\n",
    "        # Make the discriminator network trainable\n",
    "        discriminator.trainable = True\n",
    "        if index % 1 == 0:\n",
    "            loss_real = discriminator.train_on_batch(struct_batch, \n",
    "                                                 labels_real)\n",
    "            loss_fake = discriminator.train_on_batch(gen_structs, \n",
    "                                                 labels_fake)        \n",
    "            d_loss = 0.5 * np.add(loss_real, loss_fake)\n",
    "        else:\n",
    "            d_loss = 0\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        z = np.random.normal(0, 0.33, size=[batch_size, 1, 1, 1, z_size]).astype(np.float32)\n",
    "        # Train the adversarial model\n",
    "        g_loss = adversarial_model.train_on_batch(z, labels_real)\n",
    "        \n",
    "        gen_losses.append(g_loss)\n",
    "        dis_losses.append(d_loss)\n",
    "\n",
    "        write_log('g_loss', np.mean(gen_losses), counter)\n",
    "        write_log('d_loss', np.mean(dis_losses), counter)\n",
    "        counter+=1\n",
    "    if epoch % 2 == 0:\n",
    "        generate_heatmap(convert_predictions(generator(seed, training=False))[0][0], epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for ind, block in enumerate(StructureManager.globalPalette):\n",
    "    print(ind)\n",
    "    print(block['Name'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}