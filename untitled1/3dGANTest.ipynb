{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import time\n",
    "import StructureManager\n",
    "from os import system, name\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "def generate_heatmap(data, epoch):\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    im = ax.imshow(data)\n",
    "    \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            text = ax.text(j, i, data[i, j],\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.close()\n",
    "\n",
    "def build_generator():\n",
    "    \"\"\"\n",
    "    Create a Generator Model with hyperparameters values defined as follows\n",
    "    :return: Generator network\n",
    "     \"\"\"\n",
    "    z_size = 200\n",
    "    gen_filters = [64, 32, 16, 1]\n",
    "    gen_kernel_sizes = [2, 4, 4, 4]\n",
    "    gen_strides = [2, 2, 2, 2]\n",
    "    gen_input_shape = (1, 1, 1, z_size)\n",
    "    gen_activations = ['relu', 'relu', 'relu', 'tanh']\n",
    "    gen_convolutional_blocks = 4\n",
    "    \n",
    "    input_layer = layers.Input(shape=gen_input_shape)\n",
    "    # First 3D transpose convolution(or 3D deconvolution) block\n",
    "    a = layers.Conv3DTranspose(filters=gen_filters[0], \n",
    "                        kernel_size=gen_kernel_sizes[0],\n",
    "                        strides=gen_strides[0])(input_layer)\n",
    "    a = layers.BatchNormalization()(a, training=True)\n",
    "    a = layers.Activation(activation='relu')(a)\n",
    "    \n",
    "    # Next 4 3D transpose convolution(or 3D deconvolution) blocks\n",
    "    for i in range(gen_convolutional_blocks - 1):\n",
    "        a = layers.Conv3DTranspose(filters=gen_filters[i + 1], \n",
    "                            kernel_size=gen_kernel_sizes[i + 1],\n",
    "                            strides=gen_strides[i + 1], padding='same')(a)\n",
    "        a = layers.BatchNormalization()(a, training=True)\n",
    "        a = layers.Activation(activation=gen_activations[i + 1])(a)\n",
    "    gen_model = Model(inputs=[input_layer], outputs=[a])\n",
    "    gen_model.summary()\n",
    "    return gen_model\n",
    "\n",
    "def build_generator_stock():\n",
    "    \"\"\"\n",
    "    Create a Generator Model with hyperparameters values defined as follows\n",
    "    \"\"\"\n",
    "    z_size = 200\n",
    "    gen_filters = [512, 256, 128, 64, 1]\n",
    "    gen_kernel_sizes = [4, 4, 4, 4, 4]\n",
    "    gen_strides = [1, 2, 2, 2, 2]\n",
    "    gen_input_shape = (1, 1, 1, z_size)\n",
    "    gen_activations = ['relu', 'relu', 'relu', 'relu', 'sigmoid']\n",
    "    gen_convolutional_blocks = 5\n",
    "\n",
    "    input_layer = layers.Input(shape=gen_input_shape)\n",
    "\n",
    "    # First 3D transpose convolution(or 3D deconvolution) block\n",
    "    a = layers.Conv3DTranspose(filters=gen_filters[0],\n",
    "                 kernel_size=gen_kernel_sizes[0],\n",
    "                 strides=gen_strides[0])(input_layer)\n",
    "    a = layers.BatchNormalization()(a, training=True)\n",
    "    a = layers.Activation(activation='relu')(a)\n",
    "\n",
    "    # Next 4 3D transpose convolution(or 3D deconvolution) blocks\n",
    "    for i in range(gen_convolutional_blocks - 1):\n",
    "        a = layers.Conv3DTranspose(filters=gen_filters[i + 1],\n",
    "                     kernel_size=gen_kernel_sizes[i + 1],\n",
    "                     strides=gen_strides[i + 1], padding='same')(a)\n",
    "        a = layers.BatchNormalization()(a, training=True)\n",
    "        a = layers.Activation(activation=gen_activations[i + 1])(a)\n",
    "\n",
    "    gen_model = Model(inputs=[input_layer], outputs=[a])\n",
    "    gen_model.summary()\n",
    "    return gen_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    \"\"\"\n",
    "    Create a Discriminator Model using hyperparameters values defined as follows\n",
    "    :return: Discriminator network\n",
    "    \"\"\"\n",
    "    dis_input_shape = (16, 16, 16, 1)\n",
    "    dis_filters = [16, 32, 64, 1]\n",
    "    dis_kernel_sizes = [4, 4, 4, 2]\n",
    "    dis_strides = [2, 2, 2, 2]\n",
    "    dis_paddings = ['same', 'same', 'same', 'valid']\n",
    "    dis_alphas = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "    dis_activations = ['leaky_relu', 'leaky_relu', 'leaky_relu', 'sigmoid']\n",
    "    dis_convolutional_blocks = 4\n",
    "\n",
    "    dis_input_layer = layers.Input(shape=dis_input_shape)\n",
    "    \n",
    "    # The first 3D Convolutional block\n",
    "    a = layers.Conv3D(filters=dis_filters[0],\n",
    "               kernel_size=dis_kernel_sizes[0],\n",
    "               strides=dis_strides[0],\n",
    "               padding=dis_paddings[0])(dis_input_layer)\n",
    "    #a = layers.BatchNormalization()(a, training=True)\n",
    "    a = layers.LeakyReLU(dis_alphas[0])(a)\n",
    "    \n",
    "    # Next 3D Convolutional Blocks\n",
    "    for i in range(dis_convolutional_blocks - 1):\n",
    "        a = layers.Conv3D(filters=dis_filters[i + 1],\n",
    "                   kernel_size=dis_kernel_sizes[i + 1],\n",
    "                   strides=dis_strides[i + 1],\n",
    "                   padding=dis_paddings[i + 1])(a)\n",
    "        a = layers.BatchNormalization()(a, training=True)\n",
    "        if dis_activations[i + 1] == 'leaky_relu':\n",
    "            a = layers.LeakyReLU(dis_alphas[i + 1])(a)\n",
    "        elif dis_activations[i + 1] == 'sigmoid':\n",
    "            a = layers.Activation(activation='sigmoid')(a)\n",
    "    \n",
    "    dis_model = Model(inputs=[dis_input_layer], outputs=[a])\n",
    "    print(dis_model.summary())\n",
    "    return dis_model\n",
    "\n",
    "def build_discriminator_stock():\n",
    "    \"\"\"\n",
    "    Create a Discriminator Model using hyperparameters values defined as follows\n",
    "    \"\"\"\n",
    "\n",
    "    dis_input_shape = (16, 16, 16, 1)\n",
    "    dis_filters = [64, 128, 256, 512, 1]\n",
    "    dis_kernel_sizes = [4, 4, 4, 4, 4]\n",
    "    dis_strides = [2, 2, 2, 2, 1]\n",
    "    dis_paddings = ['same', 'same', 'same', 'same', 'valid']\n",
    "    dis_alphas = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "    dis_activations = ['leaky_relu', 'leaky_relu', 'leaky_relu',\n",
    "                       'leaky_relu', 'sigmoid']\n",
    "    dis_convolutional_blocks = 5\n",
    "\n",
    "    dis_input_layer = layers.Input(shape=dis_input_shape)\n",
    "    a = layers.Dense(64*64*64)(dis_input_layer)\n",
    "    a = layers.Reshape((64,64,64,1))(a)\n",
    "    # The first 3D Convolutional block\n",
    "    a = layers.Conv3D(filters=dis_filters[0],\n",
    "               kernel_size=dis_kernel_sizes[0],\n",
    "               strides=dis_strides[0],\n",
    "               padding=dis_paddings[0])(a)\n",
    "    # a = BatchNormalization()(a, training=True)\n",
    "    a = layers.LeakyReLU(dis_alphas[0])(a)\n",
    "\n",
    "    # Next 4 3D Convolutional Blocks\n",
    "    for i in range(dis_convolutional_blocks - 1):\n",
    "        a = layers.Conv3D(filters=dis_filters[i + 1],\n",
    "                   kernel_size=dis_kernel_sizes[i + 1],\n",
    "                   strides=dis_strides[i + 1],\n",
    "                   padding=dis_paddings[i + 1])(a)\n",
    "        a = layers.BatchNormalization()(a, training=True)\n",
    "        if dis_activations[i + 1] == 'leaky_relu':\n",
    "            a = layers.LeakyReLU(dis_alphas[i + 1])(a)\n",
    "        elif dis_activations[i + 1] == 'sigmoid':\n",
    "            a = layers.Activation(activation='sigmoid')(a)\n",
    "\n",
    "    dis_model = Model(inputs=[dis_input_layer], outputs=[a])\n",
    "    dis_model.summary()\n",
    "    return dis_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "def generate_save_structures(model, epoch, test_input):\n",
    "  predictions = model(test_input, training=False)\n",
    "  predictions_processed = convert_predictions(predictions)\n",
    "  generate_heatmap(predictions_processed[0], epoch)\n",
    "  for prediction in predictions_processed:\n",
    "      StructureManager.create_nbt_from_3d(np.squeeze(prediction), epoch)\n",
    "      \n",
    "def convert_predictions(data):\n",
    "      processed_predictions = np.around(np.squeeze(np.divide(np.multiply(np.add(data, 1), scalar),2)))\n",
    "      processed_predictions = processed_predictions.astype(int)\n",
    "      return processed_predictions\n",
    "\n",
    "def get_structures(model, test_input):\n",
    "  predictions = model(test_input, training=False)\n",
    "  processed_predictions = convert_predictions(predictions)\n",
    "  return processed_predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "def write_log(name, value, epoch):\n",
    "    tf.summary.scalar(name, value, epoch)\n",
    "    \n",
    "def clear_trash():\n",
    "    import glob\n",
    "    import os\n",
    "    files = glob.glob(\"*.png\")\n",
    "    files.extend(glob.glob(\"*.nbt\"))\n",
    "    files.extend(\"logs/\")\n",
    "    for file in files:\n",
    "        os.remove(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "gen_learning_rate = 0.0025\n",
    "dis_learning_rate = 10e-5\n",
    "beta = 0.5\n",
    "batch_size = 2\n",
    "z_size = 200\n",
    "DIR_PATH = ''\n",
    "generated_structures_dir = 'generated_volumes'\n",
    "log_dir = '.\\\\logs'\n",
    "epochs = 100000\n",
    "seed = np.random.normal(0, 0.33, size=[1, 1, 1, 1, z_size]).astype(np.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"model_49\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_54 (InputLayer)        [(None, 1, 1, 1, 200)]    0         \n_________________________________________________________________\nconv3d_transpose_78 (Conv3DT (None, 2, 2, 2, 64)       102464    \n_________________________________________________________________\nbatch_normalization_141 (Bat (None, 2, 2, 2, 64)       256       \n_________________________________________________________________\nactivation_92 (Activation)   (None, 2, 2, 2, 64)       0         \n_________________________________________________________________\nconv3d_transpose_79 (Conv3DT (None, 4, 4, 4, 32)       131104    \n_________________________________________________________________\nbatch_normalization_142 (Bat (None, 4, 4, 4, 32)       128       \n_________________________________________________________________\nactivation_93 (Activation)   (None, 4, 4, 4, 32)       0         \n_________________________________________________________________\nconv3d_transpose_80 (Conv3DT (None, 8, 8, 8, 16)       32784     \n_________________________________________________________________\nbatch_normalization_143 (Bat (None, 8, 8, 8, 16)       64        \n_________________________________________________________________\nactivation_94 (Activation)   (None, 8, 8, 8, 16)       0         \n_________________________________________________________________\nconv3d_transpose_81 (Conv3DT (None, 16, 16, 16, 1)     1025      \n_________________________________________________________________\nbatch_normalization_144 (Bat (None, 16, 16, 16, 1)     4         \n_________________________________________________________________\nactivation_95 (Activation)   (None, 16, 16, 16, 1)     0         \n=================================================================\nTotal params: 267,829\nTrainable params: 267,603\nNon-trainable params: 226\n_________________________________________________________________\n\n\n",
      "Model: \"model_50\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_55 (InputLayer)        [(None, 16, 16, 16, 1)]   0         \n_________________________________________________________________\nconv3d_76 (Conv3D)           (None, 8, 8, 8, 16)       1040      \n_________________________________________________________________\nleaky_re_lu_58 (LeakyReLU)   (None, 8, 8, 8, 16)       0         \n_________________________________________________________________\nconv3d_77 (Conv3D)           (None, 4, 4, 4, 32)       32800     \n_________________________________________________________________\nbatch_normalization_145 (Bat (None, 4, 4, 4, 32)       128       \n_________________________________________________________________\nleaky_re_lu_59 (LeakyReLU)   (None, 4, 4, 4, 32)       0         \n_________________________________________________________________\nconv3d_78 (Conv3D)           (None, 2, 2, 2, 64)       131136    \n_________________________________________________________________\nbatch_normalization_146 (Bat (None, 2, 2, 2, 64)       256       \n_________________________________________________________________\nleaky_re_lu_60 (LeakyReLU)   (None, 2, 2, 2, 64)       0         \n_________________________________________________________________\nconv3d_79 (Conv3D)           (None, 1, 1, 1, 1)        513       \n_________________________________________________________________\nbatch_normalization_147 (Bat (None, 1, 1, 1, 1)        4         \n_________________________________________________________________\nactivation_96 (Activation)   (None, 1, 1, 1, 1)        0         \n=================================================================\nTotal params: 165,877\nTrainable params: 165,683\nNon-trainable params: 194\n_________________________________________________________________\nNone\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Create instances\n",
    "generator = build_generator()\n",
    "print(\"\\n\")\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# Specify optimizer \n",
    "gen_optimizer = tf.keras.optimizers.Adam(lr=gen_learning_rate, beta_1=beta)\n",
    "dis_optimizer = tf.keras.optimizers.Adam(lr=dis_learning_rate, beta_1=beta)\n",
    "\n",
    "# Compile networks\n",
    "generator.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=dis_optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "input_layer = layers.Input(shape=(1, 1, 1, z_size))\n",
    "generated_structs = generator(input_layer)\n",
    "validity = discriminator(generated_structs)\n",
    "adversarial_model = Model(inputs=[input_layer], outputs=[validity])\n",
    "adversarial_model.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "dir = \"{}\\{}\".format(log_dir, time.time())\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=dir)\n",
    "tensorboard.set_model(generator)\n",
    "tensorboard.set_model(discriminator)\n",
    "writer = tf.summary.create_file_writer(dir)\n",
    "writer.set_as_default()\n",
    "labels_real = np.reshape(np.ones((batch_size,)), (-1, 1, 1, 1, 1))\n",
    "labels_fake = np.reshape(np.zeros((batch_size,)), (-1, 1, 1, 1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "d = \"..\\\\lamps484\"\n",
    "d2 = \"..\\\\structures16\"\n",
    "dataset_list = StructureManager.load_structure_blocks(d2, (16,16,16))\n",
    "\n",
    "scalar = len(StructureManager.globalPalette)-1\n",
    "processed_inputs = np.subtract(np.multiply(np.divide(dataset_list, scalar),2),1)\n",
    "processed_inputs = np.expand_dims(processed_inputs, axis=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "processed_inputs = np.full((batch_size,64,64,64, 1), 1).astype(np.float)\n",
    "fake_inputs = np.full((batch_size,64,64,64, 1), -1).astype(np.float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.8009240031242371\n0.046104066\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "counter = 0\n",
    "for epoch in range(epochs):\n",
    "    gen_losses = []\n",
    "    dis_losses = []\n",
    "    number_of_batches = int(processed_inputs.shape[0] / batch_size)\n",
    "    for index in range(number_of_batches):\n",
    "        z_sample = np.random.normal(0, 0.33, size=[batch_size, 1, 1, 1, z_size]).astype(np.float32)\n",
    "        struct_batch = processed_inputs[index * batch_size:(index + 1) * batch_size, :, :, :]\n",
    "        gen_structs = generator.predict_on_batch(z_sample)\n",
    "        # Make the discriminator network trainable\n",
    "        discriminator.trainable = True\n",
    "        for i in range(1):\n",
    "            if False:\n",
    "                loss_real = discriminator.train_on_batch(struct_batch, \n",
    "                                                     labels_fake)\n",
    "                loss_fake = discriminator.train_on_batch(gen_structs, \n",
    "                                                     labels_real)\n",
    "            else:\n",
    "                loss_real = discriminator.train_on_batch(struct_batch, \n",
    "                                                     labels_real)\n",
    "                loss_fake = discriminator.train_on_batch(gen_structs, \n",
    "                                                     labels_fake)\n",
    "        d_loss = 0.5 * np.add(loss_real, loss_fake)\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        \n",
    "        z = np.random.normal(0, 0.33, size=[batch_size, 1, 1, 1, z_size]).astype(np.float32)\n",
    "\n",
    "        for i in range(1):\n",
    "            g_loss = adversarial_model.train_on_batch(z, labels_real)\n",
    "        \n",
    "        gen_losses.append(g_loss)\n",
    "        dis_losses.append(d_loss)\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            print(d_loss)\n",
    "            print(g_loss)\n",
    "\n",
    "    write_log('g_loss', np.mean(gen_losses), counter)\n",
    "    write_log('d_loss', np.mean(dis_losses), counter)\n",
    "    counter+=1\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        predictions = generator.predict(seed, verbose=3)\n",
    "        predictions_processed = convert_predictions(predictions)\n",
    "        generate_heatmap(predictions_processed[0], epoch)\n",
    "        #print(np.sum(np.equal(predictions,lastpred)))\n",
    "        #lastpred = predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for ind, block in enumerate(StructureManager.globalPalette):\n",
    "    print(ind)\n",
    "    print(block['Name'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "predictions = generator.predict(seed)\n",
    "print(np.equal(lastpred, predictions))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-09236a3cd980>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclear_trash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-bac874bc700f>\u001b[0m in \u001b[0;36mclear_trash\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"logs/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'l'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'l'",
     "output_type": "error"
    }
   ],
   "source": [
    "clear_trash()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import imageio\n",
    "import glob\n",
    "\n",
    "images = []\n",
    "for file_name in glob.glob('*.png'):\n",
    "    images.append(imageio.imread(file_name))\n",
    "imageio.mimsave('movie.gif', images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}